{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\joshc\\anaconda3\\envs\\main\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "num_classes = 8\n",
    "resnet_weights_path = 'imagenet'\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Say not to train first layer (ResNet) model. It is already trained\n",
    "my_new_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5105 images belonging to 8 classes.\n",
      "Found 635 images belonging to 8 classes.\n",
      "Epoch 1/20\n",
      " 1/10 [==>...........................] - ETA: 57s - loss: 2.5974 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshc\\anaconda3\\envs\\main\\lib\\site-packages\\PIL\\Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 5s - loss: 2.0695 - acc: 0.2500 Epoch 1/20\n",
      "10/10 [==============================] - 56s 6s/step - loss: 2.0244 - acc: 0.2625 - val_loss: 1.9390 - val_acc: 0.2188\n",
      "Epoch 2/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 1.6852 - acc: 0.3565 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.6587 - acc: 0.3750 - val_loss: 1.3237 - val_acc: 0.4375\n",
      "Epoch 3/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 1.5153 - acc: 0.4352 Epoch 1/20\n",
      "10/10 [==============================] - 55s 5s/step - loss: 1.5088 - acc: 0.4375 - val_loss: 1.4110 - val_acc: 0.4062\n",
      "Epoch 4/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 1.4434 - acc: 0.4861 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.4108 - acc: 0.5042 - val_loss: 1.3439 - val_acc: 0.3750\n",
      "Epoch 5/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 1.2408 - acc: 0.5833 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.2808 - acc: 0.5583 - val_loss: 0.9168 - val_acc: 0.6562\n",
      "Epoch 6/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 1.2274 - acc: 0.5602 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.2093 - acc: 0.5667 - val_loss: 0.9712 - val_acc: 0.5938\n",
      "Epoch 7/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 1.0799 - acc: 0.6250 Epoch 1/20\n",
      "10/10 [==============================] - 55s 6s/step - loss: 1.0915 - acc: 0.6375 - val_loss: 0.8321 - val_acc: 0.7500\n",
      "Epoch 8/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.9222 - acc: 0.6944 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.9632 - acc: 0.6667 - val_loss: 1.0289 - val_acc: 0.5938\n",
      "Epoch 9/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 1.0346 - acc: 0.6389 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.0550 - acc: 0.6333 - val_loss: 0.8267 - val_acc: 0.6250\n",
      "Epoch 10/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.8874 - acc: 0.7222 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.8764 - acc: 0.7333 - val_loss: 1.0294 - val_acc: 0.4375\n",
      "Epoch 11/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 0.9167 - acc: 0.7033Epoch 1/20\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.8816 - acc: 0.7124 - val_loss: 0.9808 - val_acc: 0.5625\n",
      "Epoch 12/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.9185 - acc: 0.6898 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.9142 - acc: 0.6917 - val_loss: 1.0976 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.8421 - acc: 0.7315 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.8425 - acc: 0.7333 - val_loss: 1.1921 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.8466 - acc: 0.7130 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.8481 - acc: 0.7125 - val_loss: 0.7440 - val_acc: 0.6562\n",
      "Epoch 15/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.8840 - acc: 0.7222 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.8610 - acc: 0.7292 - val_loss: 0.7198 - val_acc: 0.7812\n",
      "Epoch 16/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.7526 - acc: 0.7731 Epoch 1/20\n",
      "10/10 [==============================] - 53s 5s/step - loss: 0.7770 - acc: 0.7583 - val_loss: 0.6560 - val_acc: 0.7188\n",
      "Epoch 17/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.6825 - acc: 0.7824 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.7007 - acc: 0.7792 - val_loss: 0.6999 - val_acc: 0.6562\n",
      "Epoch 18/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.7814 - acc: 0.7454 Epoch 1/20\n",
      "10/10 [==============================] - 55s 6s/step - loss: 0.8122 - acc: 0.7292 - val_loss: 0.7361 - val_acc: 0.6250\n",
      "Epoch 19/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.7489 - acc: 0.7593 Epoch 1/20\n",
      "10/10 [==============================] - 55s 5s/step - loss: 0.7513 - acc: 0.7625 - val_loss: 0.6533 - val_acc: 0.7812\n",
      "Epoch 20/20\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 0.7241 - acc: 0.7639 Epoch 1/20\n",
      "10/10 [==============================] - 54s 5s/step - loss: 0.7096 - acc: 0.7708 - val_loss: 0.8249 - val_acc: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c31f645308>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        'output/train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=24,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        'output/val',\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical')\n",
    "\n",
    "my_new_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10,\n",
    "        epochs = 20,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = data_generator.flow_from_directory(\n",
    "        'output/test',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=24,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_new_model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('class_indices1000.npy',train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.save(\"model1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "model1 = load_model('multpleFish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "list = []\n",
    "for filepath in glob.iglob(r'C:\\Users\\joshc\\OneDrive\\Desktop\\test\\*.png'):\n",
    "    list.append(filepath)\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "for filepath in list:\n",
    "    image =cv2.imread(filepath)\n",
    "\n",
    "    ###change color of image to be displayed by matplotlib\n",
    "    im2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    ###expand from 3 to 4 dimesion\n",
    "    img1 = np.expand_dims(image, axis=0)\n",
    "\n",
    "    ##convert to an numpy arr\n",
    "    test = np.array(im2)\n",
    "\n",
    "    ##predict the image\n",
    "    result = model1.predict(img1)\n",
    "\n",
    "    ##corespoding label integer\n",
    "    y_classes = np.argmax(result, axis=1)\n",
    "\n",
    "    ###predicting on the image\n",
    "    single_pred = np.squeeze(model1.predict(img1))\n",
    "\n",
    "\n",
    "    ##get labels\n",
    "    labels = np.load('class_indicies' + '.npy', allow_pickle=True).item()\n",
    "    class_indices = labels\n",
    "\n",
    "    ###\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    prediction = [labels[k] for k in y_classes]\n",
    "    results=pd.DataFrame({\"Predictions\":prediction})\n",
    "\n",
    "\n",
    "    ##get percents\n",
    "    results_dict = dict(zip(class_indices.keys(), single_pred))\n",
    "\n",
    "\n",
    "    ##Saves prediction as a string\n",
    "    prediction = prediction.pop(0)\n",
    "\n",
    "    print(results_dict)\n",
    "    plt.imshow(test)\n",
    "    plt.title(prediction)\n",
    "    plt.show()\n",
    "\n",
    "    cv2.imshow(prediction, image)\n",
    "\n",
    "\n",
    "###Ends program\n",
    "while True:\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(5, 5, figsize = (15, 15))\n",
    "i =0\n",
    "for filename in list:\n",
    "    image =cv2.imread(filename)\n",
    "    \n",
    "    ###change color of image to be displayed by matplotlib\n",
    "    im2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    ###expand from 3 to 4 dimesion\n",
    "    img1 = np.expand_dims(image, axis=0)\n",
    "\n",
    "    ##convert to an numpy arr\n",
    "    test = np.array(im2)\n",
    "\n",
    "    ##predict the image\n",
    "    result = model1.predict(img1)\n",
    "\n",
    "    ##corespoding label integer\n",
    "    y_classes = np.argmax(result, axis=1)\n",
    "\n",
    "    ###predicting on the image\n",
    "    single_pred = np.squeeze(model1.predict(img1))\n",
    "\n",
    "\n",
    "    ##get labels\n",
    "    labels = np.load('class_indicies' + '.npy', allow_pickle=True).item()\n",
    "    class_indices = labels\n",
    "\n",
    "    ###\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    prediction = [labels[k] for k in y_classes]\n",
    "    results=pd.DataFrame({\"Predictions\":prediction})\n",
    "\n",
    "\n",
    "    ##get percents\n",
    "    results_dict = dict(zip(class_indices.keys(), single_pred))\n",
    "\n",
    "\n",
    "    ##Saves prediction as a string\n",
    "    prediction = prediction.pop(0)\n",
    "\n",
    "    ax[i//5, i%5].imshow(im2)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_title(\"Predicted:{}\".format(prediction))    \n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
