{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.15\n",
      "  Downloading https://files.pythonhosted.org/packages/94/a9/7a9ff9b51a6acf5cf113e79e4cfd68a88045321cfc65802c16169dfcd041/tensorflow-1.15.0-cp37-cp37m-win_amd64.whl (295.1MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (1.16.5)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (0.8.0)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0 (from tensorflow==1.15)\n",
      "  Using cached https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (1.16.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (3.11.2)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (0.33.6)\n",
      "Collecting tensorflow-estimator==1.15.1 (from tensorflow==1.15)\n",
      "  Using cached https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (0.1.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorflow==1.15) (3.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\josh\\anaconda3\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (41.4.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\josh\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.8.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 1.14.0\n",
      "    Can't uninstall 'tensorboard'. No files were found to uninstall.\n",
      "  Found existing installation: tensorflow-estimator 1.14.0\n",
      "    Can't uninstall 'tensorflow-estimator'. No files were found to uninstall.\n",
      "  Found existing installation: tensorflow 1.14.0\n",
      "    Can't uninstall 'tensorflow'. No files were found to uninstall.\n",
      "Successfully installed tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3012, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2806, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3003, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2806, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 517, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\check.py\", line 110, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\check.py\", line 49, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2727, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3014, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3023, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3005, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 1419, in get_metadata\n",
      "    value = self._get(self._fn(self.egg_info, name))\n",
      "  File \"C:\\Users\\Josh\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 1607, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\users\\\\josh\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow-1.14.0.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "resnet_weights_path = 'imagenet'\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Say not to train first layer (ResNet) model. It is already trained\n",
    "my_new_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.5708 - acc: 0.7167 - val_loss: 0.7026 - val_acc: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de62244848>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        'Fish1/train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=24,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        'Fish1/valid',\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical')\n",
    "\n",
    "my_new_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=6,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = data_generator.flow_from_directory(\n",
    "        'Fish1/test',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=24,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_new_model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09797892, 0.90202105],\n",
       "       [0.09388098, 0.90611905],\n",
       "       [0.07895546, 0.9210445 ],\n",
       "       [0.22889045, 0.7711095 ],\n",
       "       [0.21582119, 0.78417885],\n",
       "       [0.02207362, 0.97792643],\n",
       "       [0.23519814, 0.76480186],\n",
       "       [0.05349937, 0.94650066],\n",
       "       [0.06394073, 0.93605924],\n",
       "       [0.76560146, 0.23439863]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.save(\"bass_trout_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "model1 = load_model('bass_trout_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05349937, 0.94650066],\n",
       "       [0.22889045, 0.7711095 ],\n",
       "       [0.09797892, 0.90202105],\n",
       "       [0.23519814, 0.76480186],\n",
       "       [0.76560146, 0.23439863],\n",
       "       [0.09388098, 0.90611905],\n",
       "       [0.07895546, 0.9210445 ],\n",
       "       [0.02207362, 0.97792643],\n",
       "       [0.06394073, 0.93605924],\n",
       "       [0.21582119, 0.78417885]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill\n",
      "  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "Building wheels for collected packages: dill\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78598 sha256=64e396e1956ce60469b21e19914600b450518e170f6e20fb478f83bf4b2602ed\n",
      "  Stored in directory: C:\\Users\\Josh\\AppData\\Local\\pip\\Cache\\wheels\\59\\b1\\91\\f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "Successfully built dill\n",
      "Installing collected packages: dill\n",
      "Successfully installed dill-0.3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread._local objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-7e332e321635>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_new_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle _thread._local objects"
     ]
    }
   ],
   "source": [
    "pickle.dump(my_new_model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
